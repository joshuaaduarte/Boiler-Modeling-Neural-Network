{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4313cf99-8ea7-45c4-ac26-4ae8e269b478",
   "metadata": {},
   "source": [
    "### Task 1.1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f09d8b24-9e5b-4b71-aeab-7a2e07f10023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [1.05192308e-02 8.58653846e+02 9.64920577e-02]\n",
      "standard deviation: [2.07077080e-03 1.97026246e+02 3.63777177e-02]\n",
      "Normalized input data:\n",
      " [[0.76051188 0.64053751 0.6380836 ]\n",
      " [0.76051188 0.75699888 0.75332625]\n",
      " [0.76051188 0.87346025 0.87012343]\n",
      " [0.76051188 0.98992161 0.96868076]\n",
      " [0.76051188 1.10638298 1.10216325]\n",
      " [0.76051188 1.22284434 1.19398428]\n",
      " [0.76051188 1.33930571 1.33378853]\n",
      " [0.76051188 0.98992161 0.98619516]\n",
      " [0.76051188 0.64053751 0.45578881]\n",
      " [0.76051188 0.87346025 0.62150193]\n",
      " [0.76051188 1.10638298 0.78721505]\n",
      " [0.76051188 1.22284434 0.86463075]\n",
      " [0.76051188 1.33930571 0.95240999]\n",
      " [0.76051188 0.98992161 0.70441031]\n",
      " [0.76051188 0.64053751 0.35443332]\n",
      " [0.76051188 0.87346025 0.48335584]\n",
      " [0.76051188 1.10638298 0.61227837]\n",
      " [0.76051188 1.33930571 0.74099363]\n",
      " [0.76051188 0.98992161 0.54781711]\n",
      " [1.04570384 0.64053751 0.8767561 ]\n",
      " [1.04570384 0.87346025 1.19595335]\n",
      " [1.04570384 1.10638298 1.51515061]\n",
      " [1.04570384 1.33930571 1.83434786]\n",
      " [1.04570384 0.98992161 1.35555198]\n",
      " [1.04570384 0.64053751 0.6266837 ]\n",
      " [1.04570384 0.87346025 0.85457811]\n",
      " [1.04570384 1.10638298 1.08195433]\n",
      " [1.04570384 1.22284434 1.17522626]\n",
      " [1.04570384 1.33930571 1.30995237]\n",
      " [1.04570384 0.98992161 0.96795531]\n",
      " [1.04570384 0.64053751 0.48708672]\n",
      " [1.04570384 0.87346025 0.66461429]\n",
      " [1.04570384 1.10638298 0.84193458]\n",
      " [1.04570384 1.33930571 1.01915124]\n",
      " [1.04570384 0.98992161 0.75333661]\n",
      " [1.04570384 0.81522956 0.90365987]\n",
      " [1.23583181 0.64053751 1.0368729 ]\n",
      " [1.23583181 0.87346025 1.41400239]\n",
      " [1.23583181 1.10638298 1.79102824]\n",
      " [1.23583181 1.33930571 2.16805409]\n",
      " [1.23583181 0.98992161 1.60251531]\n",
      " [1.23583181 0.64053751 0.74068272]\n",
      " [1.23583181 0.87346025 1.00992768]\n",
      " [1.23583181 1.10638298 1.27927627]\n",
      " [1.23583181 1.22284434 1.37855906]\n",
      " [1.23583181 1.33930571 1.54831396]\n",
      " [1.23583181 0.98992161 1.14465379]\n",
      " [1.23583181 0.64053751 0.57600596]\n",
      " [1.23583181 0.87346025 0.78555688]\n",
      " [1.23583181 1.10638298 0.99500417]\n",
      " [1.23583181 1.33930571 1.20424419]\n",
      " [1.23583181 0.98992161 0.89022871]]\n",
      "output data:\n",
      " [[  0.525 306.7  ]\n",
      " [  0.525 298.5  ]\n",
      " [  0.525 294.5  ]\n",
      " [  0.525 290.2  ]\n",
      " [  0.524 286.9  ]\n",
      " [  0.524 284.1  ]\n",
      " [  0.525 281.7  ]\n",
      " [  0.524 290.3  ]\n",
      " [  0.734 307.9  ]\n",
      " [  0.735 295.5  ]\n",
      " [  0.735 287.8  ]\n",
      " [  0.735 285.   ]\n",
      " [  0.735 282.5  ]\n",
      " [  0.734 291.3  ]\n",
      " [  0.945 308.6  ]\n",
      " [  0.945 296.2  ]\n",
      " [  0.945 288.5  ]\n",
      " [  0.945 283.1  ]\n",
      " [  0.945 291.9  ]\n",
      " [  0.525 328.   ]\n",
      " [  0.525 311.2  ]\n",
      " [  0.525 300.8  ]\n",
      " [  0.525 293.6  ]\n",
      " [  0.525 305.5  ]\n",
      " [  0.735 329.6  ]\n",
      " [  0.735 312.6  ]\n",
      " [  0.735 302.   ]\n",
      " [  0.735 299.4  ]\n",
      " [  0.735 294.8  ]\n",
      " [  0.735 306.8  ]\n",
      " [  0.945 330.7  ]\n",
      " [  0.945 313.6  ]\n",
      " [  0.944 302.9  ]\n",
      " [  0.945 295.6  ]\n",
      " [  0.944 307.7  ]\n",
      " [  0.734 324.7  ]\n",
      " [  0.525 342.2  ]\n",
      " [  0.524 322.3  ]\n",
      " [  0.524 310.   ]\n",
      " [  0.525 301.6  ]\n",
      " [  0.524 315.5  ]\n",
      " [  0.734 344.1  ]\n",
      " [  0.735 324.   ]\n",
      " [  0.735 311.5  ]\n",
      " [  0.735 306.3  ]\n",
      " [  0.735 302.9  ]\n",
      " [  0.734 317.1  ]\n",
      " [  0.945 345.3  ]\n",
      " [  0.944 325.1  ]\n",
      " [  0.944 312.5  ]\n",
      " [  0.945 303.9  ]\n",
      " [  0.945 318.2  ]]\n",
      "Stored 'mean' (ndarray)\n",
      "Stored 'std' (ndarray)\n",
      "[[0.7605118829981713, 0.6405375139977604, 0.638083604728727], [0.7605118829981713, 0.7569988801791713, 0.7533262502473799], [0.7605118829981713, 0.8734602463605823, 0.8701234278548633], [0.7605118829981713, 0.9899216125419933, 0.9686807622867325], [0.7605118829981713, 1.1063829787234043, 1.1021632509809993], [0.7605118829981713, 1.2228443449048152, 1.193984279694602], [0.7605118829981713, 1.339305711086226, 1.3337885322167806], [0.7605118829981713, 0.9899216125419933, 0.9861951571542256], [0.7605118829981713, 0.6405375139977604, 0.4557888084451749], [0.7605118829981713, 0.8734602463605823, 0.6215019291145325], [0.7605118829981713, 1.1063829787234043, 0.78721504978389], [0.7605118829981713, 1.2228443449048152, 0.8646307478076612], [0.7605118829981713, 1.339305711086226, 0.952409993090304], [0.7605118829981713, 0.9899216125419933, 0.7044103071855057], [0.7605118829981713, 0.6405375139977604, 0.35443331625341024], [0.7605118829981713, 0.8734602463605823, 0.4833558441537735], [0.7605118829981713, 1.1063829787234043, 0.6122783720541367], [0.7605118829981713, 1.339305711086226, 0.7409936290093224], [0.7605118829981713, 0.9899216125419933, 0.547817108103955], [1.0457038391224853, 0.6405375139977604, 0.876756098100541], [1.0457038391224853, 0.8734602463605823, 1.1959533536737876], [1.0457038391224853, 1.1063829787234043, 1.5151506092470344], [1.0457038391224853, 1.339305711086226, 1.834347864820281], [1.0457038391224853, 0.9899216125419933, 1.355551981460411], [1.0457038391224853, 0.6405375139977604, 0.6266837027439683], [1.0457038391224853, 0.8734602463605823, 0.8545781069665558], [1.0457038391224853, 1.1063829787234043, 1.0819543338261997], [1.0457038391224853, 1.2228443449048152, 1.1752262591560445], [1.0457038391224853, 1.339305711086226, 1.3099523735213758], [1.0457038391224853, 0.9899216125419933, 0.9679553139786115], [1.0457038391224853, 0.6405375139977604, 0.4870867211669673], [1.0457038391224853, 0.8734602463605823, 0.6646142857114385], [1.0457038391224853, 1.1063829787234043, 0.8419345793107325], [1.0457038391224853, 1.339305711086226, 1.0191512374374374], [1.0457038391224853, 0.9899216125419933, 0.7533366137946387], [1.0457038391224853, 0.8152295632698768, 0.9036598667845718], [1.2358318098720282, 0.6405375139977604, 1.036872903250108], [1.2358318098720282, 0.8734602463605823, 1.414002388000447], [1.2358318098720282, 1.1063829787234043, 1.7910282372781974], [1.2358318098720282, 1.339305711086226, 2.168054086555948], [1.2358318098720282, 0.9899216125419933, 1.6025153126393221], [1.2358318098720282, 0.6405375139977604, 0.7406827225915564], [1.2358318098720282, 0.8734602463605823, 1.0099276803770416], [1.2358318098720282, 1.1063829787234043, 1.2792762736351155], [1.2358318098720282, 1.2228443449048152, 1.378559056375106], [1.2358318098720282, 1.339305711086226, 1.5483139604754237], [1.2358318098720282, 0.9899216125419933, 1.1446537947423732], [1.2358318098720282, 0.6405375139977604, 0.576005956648086], [1.2358318098720282, 0.8734602463605823, 0.7855568822224707], [1.2358318098720282, 1.1063829787234043, 0.9950041723242665], [1.2358318098720282, 1.339305711086226, 1.204244191480885], [1.2358318098720282, 0.9899216125419933, 0.8902287095370742]]\n",
      "[[0.76051188 0.64053751 0.6380836 ]\n",
      " [0.76051188 0.75699888 0.75332625]\n",
      " [0.76051188 0.87346025 0.87012343]\n",
      " [0.76051188 0.98992161 0.96868076]\n",
      " [0.76051188 1.10638298 1.10216325]\n",
      " [0.76051188 1.22284434 1.19398428]\n",
      " [0.76051188 1.33930571 1.33378853]\n",
      " [0.76051188 0.98992161 0.98619516]\n",
      " [0.76051188 0.64053751 0.45578881]\n",
      " [0.76051188 0.87346025 0.62150193]\n",
      " [0.76051188 1.10638298 0.78721505]\n",
      " [0.76051188 1.22284434 0.86463075]\n",
      " [0.76051188 1.33930571 0.95240999]\n",
      " [0.76051188 0.98992161 0.70441031]\n",
      " [0.76051188 0.64053751 0.35443332]\n",
      " [0.76051188 0.87346025 0.48335584]\n",
      " [0.76051188 1.10638298 0.61227837]\n",
      " [0.76051188 1.33930571 0.74099363]\n",
      " [0.76051188 0.98992161 0.54781711]\n",
      " [1.04570384 0.64053751 0.8767561 ]\n",
      " [1.04570384 0.87346025 1.19595335]\n",
      " [1.04570384 1.10638298 1.51515061]\n",
      " [1.04570384 1.33930571 1.83434786]\n",
      " [1.04570384 0.98992161 1.35555198]\n",
      " [1.04570384 0.64053751 0.6266837 ]\n",
      " [1.04570384 0.87346025 0.85457811]\n",
      " [1.04570384 1.10638298 1.08195433]\n",
      " [1.04570384 1.22284434 1.17522626]\n",
      " [1.04570384 1.33930571 1.30995237]\n",
      " [1.04570384 0.98992161 0.96795531]\n",
      " [1.04570384 0.64053751 0.48708672]\n",
      " [1.04570384 0.87346025 0.66461429]\n",
      " [1.04570384 1.10638298 0.84193458]\n",
      " [1.04570384 1.33930571 1.01915124]\n",
      " [1.04570384 0.98992161 0.75333661]\n",
      " [1.04570384 0.81522956 0.90365987]\n",
      " [1.23583181 0.64053751 1.0368729 ]\n",
      " [1.23583181 0.87346025 1.41400239]\n",
      " [1.23583181 1.10638298 1.79102824]\n",
      " [1.23583181 1.33930571 2.16805409]\n",
      " [1.23583181 0.98992161 1.60251531]\n",
      " [1.23583181 0.64053751 0.74068272]\n",
      " [1.23583181 0.87346025 1.00992768]\n",
      " [1.23583181 1.10638298 1.27927627]\n",
      " [1.23583181 1.22284434 1.37855906]\n",
      " [1.23583181 1.33930571 1.54831396]\n",
      " [1.23583181 0.98992161 1.14465379]\n",
      " [1.23583181 0.64053751 0.57600596]\n",
      " [1.23583181 0.87346025 0.78555688]\n",
      " [1.23583181 1.10638298 0.99500417]\n",
      " [1.23583181 1.33930571 1.20424419]\n",
      " [1.23583181 0.98992161 0.89022871]]\n",
      "[[0.525, 306.7], [0.525, 298.5], [0.525, 294.5], [0.525, 290.2], [0.524, 286.9], [0.524, 284.1], [0.525, 281.7], [0.524, 290.3], [0.734, 307.9], [0.735, 295.5], [0.735, 287.8], [0.735, 285.0], [0.735, 282.5], [0.734, 291.3], [0.945, 308.6], [0.945, 296.2], [0.945, 288.5], [0.945, 283.1], [0.945, 291.9], [0.525, 328.0], [0.525, 311.2], [0.525, 300.8], [0.525, 293.6], [0.525, 305.5], [0.735, 329.6], [0.735, 312.6], [0.735, 302.0], [0.735, 299.4], [0.735, 294.8], [0.735, 306.8], [0.945, 330.7], [0.945, 313.6], [0.944, 302.9], [0.945, 295.6], [0.944, 307.7], [0.734, 324.7], [0.525, 342.2], [0.524, 322.3], [0.524, 310.0], [0.525, 301.6], [0.524, 315.5], [0.734, 344.1], [0.735, 324.0], [0.735, 311.5], [0.735, 306.3], [0.735, 302.9], [0.734, 317.1], [0.945, 345.3], [0.944, 325.1], [0.944, 312.5], [0.945, 303.9], [0.945, 318.2]]\n",
      "[[  0.525 306.7  ]\n",
      " [  0.525 298.5  ]\n",
      " [  0.525 294.5  ]\n",
      " [  0.525 290.2  ]\n",
      " [  0.524 286.9  ]\n",
      " [  0.524 284.1  ]\n",
      " [  0.525 281.7  ]\n",
      " [  0.524 290.3  ]\n",
      " [  0.734 307.9  ]\n",
      " [  0.735 295.5  ]\n",
      " [  0.735 287.8  ]\n",
      " [  0.735 285.   ]\n",
      " [  0.735 282.5  ]\n",
      " [  0.734 291.3  ]\n",
      " [  0.945 308.6  ]\n",
      " [  0.945 296.2  ]\n",
      " [  0.945 288.5  ]\n",
      " [  0.945 283.1  ]\n",
      " [  0.945 291.9  ]\n",
      " [  0.525 328.   ]\n",
      " [  0.525 311.2  ]\n",
      " [  0.525 300.8  ]\n",
      " [  0.525 293.6  ]\n",
      " [  0.525 305.5  ]\n",
      " [  0.735 329.6  ]\n",
      " [  0.735 312.6  ]\n",
      " [  0.735 302.   ]\n",
      " [  0.735 299.4  ]\n",
      " [  0.735 294.8  ]\n",
      " [  0.735 306.8  ]\n",
      " [  0.945 330.7  ]\n",
      " [  0.945 313.6  ]\n",
      " [  0.944 302.9  ]\n",
      " [  0.945 295.6  ]\n",
      " [  0.944 307.7  ]\n",
      " [  0.734 324.7  ]\n",
      " [  0.525 342.2  ]\n",
      " [  0.524 322.3  ]\n",
      " [  0.524 310.   ]\n",
      " [  0.525 301.6  ]\n",
      " [  0.524 315.5  ]\n",
      " [  0.734 344.1  ]\n",
      " [  0.735 324.   ]\n",
      " [  0.735 311.5  ]\n",
      " [  0.735 306.3  ]\n",
      " [  0.735 302.9  ]\n",
      " [  0.734 317.1  ]\n",
      " [  0.945 345.3  ]\n",
      " [  0.944 325.1  ]\n",
      " [  0.944 312.5  ]\n",
      " [  0.945 303.9  ]\n",
      " [  0.945 318.2  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "xdata = []\n",
    "ydata = []\n",
    "#xdata.append([ Di(m), qoflux (kW/m^2), mdot (kg/s)])\n",
    "\n",
    "\n",
    "xdata.append([0.008, 550, 0.06157])\n",
    "xdata.append([0.008, 650, 0.07269])\n",
    "xdata.append([0.008, 750, 0.08396])\n",
    "xdata.append([0.008, 850, 0.09347])\n",
    "xdata.append([0.008, 950, 0.10635])\n",
    "xdata.append([0.008, 1050, 0.11521])\n",
    "xdata.append([0.008, 1150, 0.1287])\n",
    "xdata.append([0.008, 850, 0.09516])\n",
    "xdata.append([0.008, 550, 0.04398])\n",
    "xdata.append([0.008, 750, 0.05997])\n",
    "xdata.append([0.008, 950, 0.07596])\n",
    "xdata.append([0.008, 1050, 0.08343])\n",
    "xdata.append([0.008, 1150, 0.0919])\n",
    "xdata.append([0.008, 850, 0.06797])\n",
    "xdata.append([0.008, 550, 0.0342])\n",
    "xdata.append([0.008, 750, 0.04664])\n",
    "xdata.append([0.008, 950, 0.05908])\n",
    "xdata.append([0.008, 1150, 0.0715])\n",
    "xdata.append([0.008, 850, 0.05286])\n",
    "xdata.append([0.011, 550, 0.0846])\n",
    "xdata.append([0.011, 750, 0.1154])\n",
    "xdata.append([0.011, 950, 0.1462])\n",
    "xdata.append([0.011, 1150, 0.177])\n",
    "xdata.append([0.011, 850, 0.1308])\n",
    "xdata.append([0.011, 550, 0.06047])\n",
    "xdata.append([0.011, 750, 0.08246])\n",
    "xdata.append([0.011, 950, 0.1044])\n",
    "xdata.append([0.011, 1050, 0.1134])\n",
    "xdata.append([0.011, 1150, 0.1264])\n",
    "xdata.append([0.011, 850, 0.0934])\n",
    "xdata.append([0.011, 550, 0.047])\n",
    "xdata.append([0.011, 750, 0.06413])\n",
    "xdata.append([0.011, 950, 0.08124])\n",
    "xdata.append([0.011, 1150, 0.09834])\n",
    "xdata.append([0.011, 850, 0.072691])\n",
    "xdata.append([0.011, 700, 0.087196])\n",
    "xdata.append([0.013, 550, 0.10005])\n",
    "xdata.append([0.013, 750, 0.13644])\n",
    "xdata.append([0.013, 950, 0.17282])\n",
    "xdata.append([0.013, 1150, 0.2092])\n",
    "xdata.append([0.013, 850, 0.15463])\n",
    "xdata.append([0.013, 550, 0.07147])\n",
    "xdata.append([0.013, 750, 0.09745])\n",
    "xdata.append([0.013, 950, 0.12344])\n",
    "xdata.append([0.013, 1050, 0.13302])\n",
    "xdata.append([0.013, 1150, 0.1494])\n",
    "xdata.append([0.013, 850, 0.11045])\n",
    "xdata.append([0.013, 550, 0.05558])\n",
    "xdata.append([0.013, 750, 0.0758])\n",
    "xdata.append([0.013, 950, 0.09601])\n",
    "xdata.append([0.013, 1150, 0.1162])\n",
    "xdata.append([0.013, 850, 0.0859])\n",
    "\n",
    "#ydata.append([ exit quality, max wall temperature (deg C)])\n",
    "\n",
    "ydata.append([0.525, 306.7])\n",
    "ydata.append([0.525, 298.5])\n",
    "ydata.append([0.525, 294.5])\n",
    "ydata.append([0.525, 290.2])\n",
    "ydata.append([0.524, 286.9])\n",
    "ydata.append([0.524, 284.1])\n",
    "ydata.append([0.525, 281.7])\n",
    "ydata.append([0.524, 290.3])\n",
    "ydata.append([0.734, 307.9])\n",
    "ydata.append([0.735, 295.5])\n",
    "ydata.append([0.735, 287.8])\n",
    "ydata.append([0.735, 285.0])\n",
    "ydata.append([0.735, 282.5])\n",
    "ydata.append([0.734, 291.3])\n",
    "ydata.append([ 0.945, 308.6])\n",
    "ydata.append([0.945, 296.2])\n",
    "ydata.append([0.945, 288.5])\n",
    "ydata.append([0.945, 283.1])\n",
    "ydata.append([0.945, 291.9])\n",
    "ydata.append([ 0.525, 328.0])\n",
    "ydata.append([0.525, 311.2])\n",
    "ydata.append([0.525, 300.8])\n",
    "ydata.append([0.525, 293.6])\n",
    "ydata.append([0.525, 305.5])\n",
    "ydata.append([0.735, 329.6])\n",
    "ydata.append([0.735, 312.6])\n",
    "ydata.append([0.735, 302.0])\n",
    "ydata.append([0.735, 299.4])\n",
    "ydata.append([0.735, 294.8])\n",
    "ydata.append([0.735, 306.8])\n",
    "ydata.append([ 0.945, 330.7])\n",
    "ydata.append([0.945, 313.6])\n",
    "ydata.append([0.944, 302.9])\n",
    "ydata.append([0.945, 295.6])\n",
    "ydata.append([0.944, 307.7])\n",
    "ydata.append([0.734, 324.7])\n",
    "ydata.append([0.525, 342.2])\n",
    "ydata.append([0.524,  322.3])\n",
    "ydata.append([0.524, 310.0])\n",
    "ydata.append([0.525, 301.6])\n",
    "ydata.append([0.524, 315.5])\n",
    "ydata.append([0.734, 344.1])\n",
    "ydata.append([0.735, 324.0])\n",
    "ydata.append([0.735, 311.5])\n",
    "ydata.append([0.735, 306.3])\n",
    "ydata.append([0.735, 302.9])\n",
    "ydata.append([0.734, 317.1])\n",
    "ydata.append([0.945, 345.3])\n",
    "ydata.append([0.944, 325.1])\n",
    "ydata.append([0.944, 312.5])\n",
    "ydata.append([0.945, 303.9])\n",
    "ydata.append([0.945, 318.2])\n",
    "\n",
    "# calculating the mean and standard deviation using numpy\n",
    "mean=np.mean(xdata, axis=0)\n",
    "std=np.std(xdata, axis=0)\n",
    "print('mean:', mean)\n",
    "print('standard deviation:', std)\n",
    "#standardize the data\n",
    "Nx = []\n",
    "for i in range(len(xdata)):\n",
    "    Nx.append([ (xdata[i][0]/mean[0]) , (xdata[i][1]/mean[1]) , (xdata[i][2]/mean[2])])\n",
    "xdata = Nx\n",
    "\n",
    "xarray= np.array(xdata)\n",
    "yarray= np.array(ydata)\n",
    "print('Normalized input data:\\n', xarray)\n",
    "print('output data:\\n', yarray)\n",
    "%store mean\n",
    "%store std\n",
    "\n",
    "\n",
    "xarray= numpy.array(xdata)\n",
    "yarray= numpy.array(ydata)\n",
    "print (xdata)\n",
    "print (xarray)\n",
    "print (ydata)\n",
    "print (yarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f97b41-6432-49db-b3f8-8ff8857bcb1a",
   "metadata": {},
   "source": [
    "### Task 1.1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9fd6503-33cb-4295-a925-4d05f034467a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training input array:\n",
      "[[0.76051188 1.33930571 0.74099363]\n",
      " [0.76051188 0.87346025 0.48335584]\n",
      " [1.04570384 0.87346025 0.66461429]\n",
      " [1.23583181 1.33930571 2.16805409]\n",
      " [0.76051188 1.22284434 1.19398428]\n",
      " [0.76051188 0.98992161 0.96868076]\n",
      " [0.76051188 0.98992161 0.98619516]\n",
      " [1.23583181 1.10638298 1.27927627]\n",
      " [0.76051188 1.33930571 0.95240999]\n",
      " [0.76051188 0.64053751 0.45578881]\n",
      " [1.04570384 1.22284434 1.17522626]\n",
      " [1.04570384 0.64053751 0.6266837 ]\n",
      " [1.23583181 0.98992161 0.89022871]\n",
      " [0.76051188 0.75699888 0.75332625]\n",
      " [1.04570384 0.64053751 0.48708672]\n",
      " [1.23583181 0.98992161 1.14465379]\n",
      " [1.04570384 1.33930571 1.83434786]\n",
      " [1.23583181 0.64053751 1.0368729 ]\n",
      " [1.04570384 1.33930571 1.01915124]\n",
      " [1.04570384 1.10638298 1.51515061]\n",
      " [1.04570384 0.64053751 0.8767561 ]\n",
      " [1.04570384 1.10638298 0.84193458]\n",
      " [1.23583181 0.64053751 0.74068272]\n",
      " [0.76051188 1.22284434 0.86463075]\n",
      " [0.76051188 0.87346025 0.62150193]\n",
      " [1.23583181 1.10638298 0.99500417]\n",
      " [0.76051188 0.98992161 0.70441031]\n",
      " [1.23583181 0.87346025 1.41400239]\n",
      " [0.76051188 0.87346025 0.87012343]\n",
      " [1.04570384 1.10638298 1.08195433]\n",
      " [1.04570384 0.81522956 0.90365987]\n",
      " [1.23583181 1.22284434 1.37855906]\n",
      " [1.04570384 0.87346025 0.85457811]\n",
      " [1.04570384 0.98992161 0.75333661]\n",
      " [1.23583181 1.10638298 1.79102824]\n",
      " [0.76051188 1.10638298 0.61227837]\n",
      " [0.76051188 1.10638298 0.78721505]\n",
      " [1.23583181 0.87346025 0.78555688]\n",
      " [0.76051188 0.98992161 0.54781711]]\n",
      "validation input array:\n",
      "[[1.23583181 0.87346025 1.00992768]\n",
      " [0.76051188 1.10638298 1.10216325]\n",
      " [1.04570384 0.87346025 1.19595335]\n",
      " [1.23583181 1.33930571 1.20424419]\n",
      " [0.76051188 0.64053751 0.6380836 ]\n",
      " [0.76051188 0.64053751 0.35443332]\n",
      " [1.23583181 0.98992161 1.60251531]\n",
      " [1.04570384 0.98992161 0.96795531]\n",
      " [1.23583181 1.33930571 1.54831396]\n",
      " [0.76051188 1.33930571 1.33378853]\n",
      " [1.04570384 1.33930571 1.30995237]\n",
      " [1.04570384 0.98992161 1.35555198]\n",
      " [1.23583181 0.64053751 0.57600596]]\n",
      "training output array:\n",
      "[[  0.945 283.1  ]\n",
      " [  0.945 296.2  ]\n",
      " [  0.945 313.6  ]\n",
      " [  0.525 301.6  ]\n",
      " [  0.524 284.1  ]\n",
      " [  0.525 290.2  ]\n",
      " [  0.524 290.3  ]\n",
      " [  0.735 311.5  ]\n",
      " [  0.735 282.5  ]\n",
      " [  0.734 307.9  ]\n",
      " [  0.735 299.4  ]\n",
      " [  0.735 329.6  ]\n",
      " [  0.945 318.2  ]\n",
      " [  0.525 298.5  ]\n",
      " [  0.945 330.7  ]\n",
      " [  0.734 317.1  ]\n",
      " [  0.525 293.6  ]\n",
      " [  0.525 342.2  ]\n",
      " [  0.945 295.6  ]\n",
      " [  0.525 300.8  ]\n",
      " [  0.525 328.   ]\n",
      " [  0.944 302.9  ]\n",
      " [  0.734 344.1  ]\n",
      " [  0.735 285.   ]\n",
      " [  0.735 295.5  ]\n",
      " [  0.944 312.5  ]\n",
      " [  0.734 291.3  ]\n",
      " [  0.524 322.3  ]\n",
      " [  0.525 294.5  ]\n",
      " [  0.735 302.   ]\n",
      " [  0.734 324.7  ]\n",
      " [  0.735 306.3  ]\n",
      " [  0.735 312.6  ]\n",
      " [  0.944 307.7  ]\n",
      " [  0.524 310.   ]\n",
      " [  0.945 288.5  ]\n",
      " [  0.735 287.8  ]\n",
      " [  0.944 325.1  ]\n",
      " [  0.945 291.9  ]]\n",
      "validation output array:\n",
      "[[  0.735 324.   ]\n",
      " [  0.524 286.9  ]\n",
      " [  0.525 311.2  ]\n",
      " [  0.945 303.9  ]\n",
      " [  0.525 306.7  ]\n",
      " [  0.945 308.6  ]\n",
      " [  0.524 315.5  ]\n",
      " [  0.735 306.8  ]\n",
      " [  0.735 302.9  ]\n",
      " [  0.525 281.7  ]\n",
      " [  0.735 294.8  ]\n",
      " [  0.525 305.5  ]\n",
      " [  0.945 345.3  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_xarray,valid_xarray,train_yarray,valid_yarray = train_test_split(xarray, yarray, test_size=0.25, random_state=13)\n",
    "\n",
    "print('training input array:')\n",
    "print(train_xarray)\n",
    "print('validation input array:') \n",
    "print(valid_xarray)\n",
    "print('training output array:')\n",
    "print(train_yarray)\n",
    "print('validation output array:') \n",
    "print(valid_yarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de071b3-b409-4c23-8bed-13f087dcf8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''>>>>> start CodeP4.1F22\n",
    "    V.P. Carey ME249, Fall 2022\n",
    "\n",
    "Keras Neural Network Modeling '''\n",
    "\n",
    "#import useful packages\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the following 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# define meadian values of input variables - add your values here\n",
    "Tamed = 1.  #make sure Tamed does not = 0\n",
    "IDmed = 1.\n",
    "RLmed = 1.\n",
    "\n",
    "#create input data array\n",
    "xdata = []\n",
    "\n",
    "#Part 1 input data: Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "xdata = [[-10.0, 350, 4.464]] \n",
    "xdata.append([-10.0, 650, 4.464]) \n",
    "xdata.append([-10.0, 950, 4.464]) \n",
    "xdata.append([-10.0, 1250, 4.464])\n",
    "''' ADD THE REST OF THE INPUT DATA AND CONVERT TO:\n",
    "xdata = [[-10.0/Tamed, 350/IDmed, 4.464/RLmed]] \n",
    "xdata.append([-10.0/Tamed, 650/IDmed, 4.464/RLmed]) \n",
    "xdata.append([-10.0/Tamed, 950/IDmed, 4.464/RLmed]) \n",
    "xdata.append([-10.0/Tamed, 1250/IDmed, 4.464/RLmed]) \n",
    "... etc.'''\n",
    "\n",
    "xarray= np.array(xdata)\n",
    "print (xdata)\n",
    "print (xarray)\n",
    "\n",
    "# define meadian values of input variables - add your values here\n",
    "VLmed = 1.\n",
    "Wdmed = 1\n",
    "\n",
    "#create input data array\n",
    "ydata = []\n",
    "\n",
    "#Part 1 output data: VL (V) and Power out Wd (W)\n",
    "ydata = [[18.9, 80.3]] \n",
    "ydata.append([23.5, 124.6]) \n",
    "ydata.append([24.8, 138.6]) \n",
    "ydata.append([25.6, 146.9]) \n",
    "''' ADD THE REST OF THE OUPUT DATA AND CONVERT TO:\n",
    "ydata = [[18.9/VLmed, 80.3/Wdmed]] \n",
    "ydata.append([23.5/VLmed, 124.6/Wdmed]) \n",
    "ydata.append([24.8/VLmed, 138.6/Wdmed]) \n",
    "ydata.append([25.6/VLmed, 146.9/Wdmed]) \n",
    "... etc.'''\n",
    "\n",
    "yarray= np.array(ydata)\n",
    "print (ydata)\n",
    "print (yarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38dcc6-4d67-4548-a453-3252e6d7e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "\n",
    "#As seen below, we have created four dense layers. \n",
    "#A dense layer is a layer in neural network that’s fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 1 in our case. \n",
    "#The activation function we have chosen is elu, which stands for exponential linear unit. .\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 0.5\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(6, activation=K.elu, input_shape=[3],  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(8, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(16, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(8, activation=K.elu, kernel_initializer=initializer),\n",
    "    keras.layers.Dense(2,  kernel_initializer=initializer)\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f3dda-708a-45c9-a53e-1827e1dbe6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean squared error. After the compilation of the model, we’ll use the fit method with ~500 epochs.\n",
    "#Number of epochs can be varied.\n",
    "\n",
    "#from tf.keras import optimizers\n",
    "rms = keras.optimizers.RMSprop(0.020)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e9ae7-9c55-49a0-9319-40da147a2233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 80, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(xarray,yarray,epochs=800,callbacks=[es])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))\n",
    "\n",
    "model.save('./best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f04627-453d-4ade-a65a-d632db1212e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This line of code can be used to reconstruct the saved model.\n",
    "\n",
    "recon_model = keras.models.load_model(\"best_model\")\n",
    "\n",
    "# the name of the model is now \"recon_model\". You can then use this model to do predictions for comparisons.\n",
    "# See the previous project for code to do the comparisons.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
